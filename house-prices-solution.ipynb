{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources :\n",
    "# https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard\n",
    "# https://www.kaggle.com/juliencs/a-study-on-regression-applied-to-the-ames-dataset\n",
    "\n",
    "#### TO DO #####\n",
    "\n",
    "#   Function for preprocessing the data:\n",
    "#    OK incorporez fonction encodage avant de créer les composite features\n",
    "#    OK laisser le OHE à part\n",
    "#    OK mettre à jour les classifs de variables\n",
    "\n",
    "#   Normality tests:\n",
    "#    OK  skewness only for numerical variables (numeric continue)\n",
    "#    OK. Log1 or Log10 ?? stick to log10\n",
    "#    OK. What about composite features created : create them THEN apply Log transformation if skewed\n",
    "#    OK. Review Log10 values (some are NaN ....) ==> Log10 will 'distort' data and give some NaN values, stick to Log1p\n",
    "\n",
    "##  Feature selection :\n",
    "#    OK.settle on the method for selecting correlated feats : Pearson (default in the .corr method)\n",
    "\n",
    "#   Feature engineering :\n",
    "#    OK. add polynomial features.\n",
    "#         OK.CHECK : for which feature : numerical continuous only ? cat ordinal also ? ALL TYPES\n",
    "#         OK.CHECK : Does this add skewness ? will apply LOG TRANSFORM after\n",
    "#         OK.To DO : classify new features \n",
    "#    2. use clustering (kmeans) like in Linda's hands on workshop to create features\n",
    "#    3. remove atypical sales (foreclosure...)\n",
    "\n",
    "##  Model selection :\n",
    "#    OK. only linear regression models : yes\n",
    "#    2. tune models (epsilon for Huber Loss, grid search, Ridge regression, degree of polynomial)\n",
    "##   OK. create function to select related variables created with OHE\n",
    "\n",
    "### TEST SET :\n",
    "#    1. make sure train & validation set have the same variables (cf. Fred's notebook : encoding-cat-variables)\n",
    "#    2. test all the functions (pay attention to columns with different values than in train set...)\n",
    "#    3. can I drop outliers from the TEST set ?\n",
    "\n",
    "\n",
    "##### TOPICS to discuss ####\n",
    "# 1. Normal distribution:\n",
    "#    a. how to assess normality ? skew / kurtosis / tests / visual\n",
    "#.   b. how to achieve normality ? Log Tranform and other / to which type of variable to apply : numeric, categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 2430 entries and 82 features.\n"
     ]
    }
   ],
   "source": [
    "# loading the data\n",
    "data = pd.read_csv('house-prices.csv')\n",
    "print('Dataset has {} entries and {} features.'.format(data.shape[0], data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for preprocessing the data\n",
    "def preprocess_df(df):\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    ###  Removing outliers : very large houses (more than 4000 square feet)\n",
    "    df_clean = df_clean[df_clean['Gr Liv Area'] < 4000]\n",
    "    \n",
    "    ### Handling missing values\n",
    "    # Features that are not necessary\n",
    "    columns_to_drop = ['PID', 'Order']\n",
    "    # Features that most likely does not exist if NaN\n",
    "    columns_to_zero = ['Garage Area', 'Garage Cars', 'Total Bsmt SF', 'Bsmt Half Bath', 'Bsmt Full Bath', \n",
    "                      'BsmtFin SF 1', 'BsmtFin SF 2', 'Bsmt Unf SF']\n",
    "    # Fill with NA\n",
    "    columns_to_NA = ['Pool QC', 'Misc Feature', 'Alley', 'Fence', 'Fireplace Qu', 'Garage Type',\n",
    "                 'Garage Finish','Garage Qual','Garage Cond', 'Bsmt Qual' , 'Bsmt Cond' , 'Bsmt Exposure' ,\n",
    "                 'BsmtFin Type 1' , 'BsmtFin Type 2']\n",
    "    # ...\n",
    "    columns_to_none = ['Mas Vnr Type']\n",
    "    # \n",
    "    columns_to_mean = ['Mas Vnr Area', 'Lot Frontage']\n",
    "    #...\n",
    "    columns_to_mode = ['Electrical']\n",
    "    \n",
    "    df_clean = df_clean.drop(columns_to_drop, axis=1)\n",
    "    df_clean[columns_to_zero] = df[columns_to_zero].fillna(0)\n",
    "    df_clean[columns_to_NA] = df[columns_to_NA].fillna('NA')\n",
    "    df_clean[columns_to_none] = df[columns_to_none].fillna('None')\n",
    "    df_clean[columns_to_mean] = df[columns_to_mean].fillna(df[columns_to_mean].mean())\n",
    "    df_clean[columns_to_mode] = df[columns_to_mode].fillna(df[columns_to_mode].mode().iloc[0,0]) \n",
    "    \n",
    "    ### Feature engineering:\n",
    "    \n",
    "    ## Normalization\n",
    "    # Add a LogSalePrice variable to the DataFrame:\n",
    "    df_clean['LogSalePrice'] = np.log10(df_clean['SalePrice'])\n",
    "    # other features with skewness +- 1\n",
    "    # ...\n",
    "    \n",
    "    ## Total counts:\n",
    "    # Total surface count\n",
    "    df_clean['Total SF'] = df_clean['Total Bsmt SF'] + df_clean['Gr Liv Area']\n",
    "    \n",
    "    # Total room count\n",
    "    df_clean['Total Rooms'] = (df_clean['TotRms AbvGrd'] + df_clean['Bsmt Full Bath'] + \n",
    "                                df_clean['Bsmt Half Bath'] + df_clean['Full Bath'] + df_clean['Half Bath'])\n",
    "    \n",
    "    ## Binary features:\n",
    "    # Built before 1980 & no remodeling\n",
    "    #df_clean['Built/Re bef 80'] = (df_clean['Year Remod/Add'] >1980)*1\n",
    "    \n",
    "    # Creating a 'Remodeled' feature (if YearRemodAdd != YearBuilt) \n",
    "    df_clean['Remodeled'] = (df_clean['Year Remod/Add'] != df_clean['Year Built']) * 1\n",
    "    \n",
    "    # Creating a 'RecentRemodel' feature if a remodeling happenned in the year the house was sold\n",
    "    df_clean['RecentRemodel'] = (df_clean['Year Remod/Add'] == df_clean['Yr Sold']) * 1\n",
    "    \n",
    "    # Creating a 'NewHouse' featureWas this house sold in the year it was built?\n",
    "    df_clean['NewHouse'] = (df_clean['Year Built'] == df_clean['Yr Sold']) * 1\n",
    "\n",
    "    # Age of the house\n",
    "    #adf_cl[\"Age\"] = 2010 - df_clean[\"Year Built\"]\n",
    "       \n",
    "    # Time since sold\n",
    "    #df_clean[\"TimeSinceSold\"] = 2010 - df_clean[\"Yr Sold\"]\n",
    "    \n",
    "    # Sale seasonality feature (high & low season)\n",
    "    df_clean['Sale Season'] = df_clean['Mo Sold'].replace({1:0, 2:0, 3:0, 4:1, 5:1, 6:1, 7:1, 8:1, 9:0, 10:0, 11:0, 12:0})\n",
    "    \n",
    "    ### ENCODING\n",
    "    \n",
    "    # Encoding Ordinal variables:\n",
    "    # assigning a value from 0 (none) / 1 (poor) to 5 or 6 (excellent) to these variables\n",
    "    quality_features = ['Exter Qual', 'Exter Cond', 'Bsmt Qual', 'Bsmt Cond', 'Heating QC', 'Kitchen Qual',\n",
    "                    'Fireplace Qu', 'Garage Qual', 'Garage Cond', 'Pool QC']\n",
    "    df_clean[quality_features] = df_clean[quality_features].replace({\n",
    "        'Ex' : 5, 'Gd' : 4,'TA' : 3, 'Fa' : 2, 'Po' : 1, 'NA' : 0\n",
    "    })\n",
    "    \n",
    "    # Encoding other ordinal variables, with specific 'scales', creating a dict for each variable,\n",
    "    # and using .replace method\n",
    "    other_ord_features = {\n",
    "        'Lot Shape' : {'Reg': 4, 'IR1': 3, 'IR2' : 2, 'IR3' : 1},\n",
    "        'Utilities' : {'AllPub': 4, 'NoSewr': 3, 'NoSeWa': 2, 'ELO': 1},\n",
    "        'Land Slope' : {'Gtl' : 3, 'Mod' : 2, 'Sev' : 1},\n",
    "        'Bsmt Exposure' : {'Gd' : 4, 'Av' : 3,'Mn' : 2, 'No' : 1, 'NA' : 0},\n",
    "        'BsmtFin Type 1' : {'GLQ' : 6, 'ALQ' : 5,'BLQ' : 4, 'Rec' : 3, 'LwQ' : 2, 'Unf' : 1, 'NA' : 0},\n",
    "        'BsmtFin Type 2' : {'GLQ' : 6, 'ALQ' : 5,'BLQ' : 4, 'Rec' : 3, 'LwQ' : 2, 'Unf' : 1, 'NA' : 0},\n",
    "        'Electrical' : {'SBrkr' : 5, 'FuseA' : 4,'FuseF' : 3, 'FuseP' : 2, 'Mix' : 1},\n",
    "        'Functional' : {'Typ' : 8, 'Min1' : 7,'Min2' : 6, 'Mod' : 5, 'Maj1' : 4, 'Maj2' : 3, 'Sev' : 2, 'Sal':1},\n",
    "        'Garage Finish' : {'Fin' : 3, 'RFn' : 2,'Unf' : 1, 'NA' : 0},\n",
    "        'Paved Drive' : {'Y' : 3, 'P' : 2,'N' : 1},\n",
    "        'Fence' : {'GdPrv' : 4, 'MnPrv' : 3,'GdWo' : 2, 'MnWw' : 1, 'NA' : 0}\n",
    "    }\n",
    "    df_clean = df_clean.replace(other_ord_features)  \n",
    "                               \n",
    "    ### Feature engineering continued:\n",
    "    \n",
    "    ## Composite features :\n",
    "    # Overall quality of the house\n",
    "    df_clean['Overall Grade'] = df_clean['Overall Qual'] * df_clean['Overall Cond']\n",
    "\n",
    "    # Overall quality of the garage\n",
    "    df_clean['Garage Grade'] = df_clean['Garage Qual'] * df_clean['Garage Cond']\n",
    "    \n",
    "    # Overall quality of the exterior\n",
    "    df_clean['Exter Grade'] = df_clean['Exter Qual'] * df_clean['Exter Cond']\n",
    "    \n",
    "    # Composite of two most correlated features to the Sale Price : TotalSF & Overall Quality\n",
    "    df_clean['OverallQualxTotalSF'] = df_clean['Total SF'] * df_clean['Overall Qual']\n",
    "    \n",
    "                               \n",
    "    ## Binning years columns\n",
    " \n",
    "    #To DO : replicate to other years columns:\n",
    "    #cols_to_bin = ['Year Built', 'Year Remod/Add', 'Garage Yr Blt', 'Yr Sold']    #keep Yr Sold ? \n",
    "    \n",
    "    pd.options.mode.chained_assignment = None  # disabling warnings on chained assignment, I think this is the right \n",
    "                                                #choice as I am working on a copy anyway\n",
    "    df_clean['Garage Yr Blt'].loc[df_clean['Garage Yr Blt'] <= 1960] = 1\n",
    "    df_clean['Garage Yr Blt'].loc[(df_clean['Garage Yr Blt'] > 1960) & (df_clean['Garage Yr Blt'] <= 1978)] = 2\n",
    "    df_clean['Garage Yr Blt'].loc[(df_clean['Garage Yr Blt'] > 1978) & (df_clean['Garage Yr Blt'] <= 2002)] = 3\n",
    "    df_clean['Garage Yr Blt'].loc[df_clean['Garage Yr Blt'] > 2002] = 4\n",
    "    #create a specific bin for misssing values\n",
    "    df_clean['Garage Yr Blt'].loc[df_clean['Garage Yr Blt'].isnull()] = 0\n",
    "    \n",
    "    # Add polynomial features for the 10 most correlated features\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "    def add_poly(a):\n",
    "        return poly.fit_transform(df_clean[a][:, np.newaxis])[:,1], poly.fit_transform(df_clean[a][:, np.newaxis])[:,2]\n",
    "\n",
    "    df_clean['OverallQualxTotalSF_1'], df_clean['OverallQualxTotalSF_2'] = add_poly('OverallQualxTotalSF')\n",
    "    df_clean['Total SF_1'], df_clean['Total SF_2'] = add_poly('Total SF')\n",
    "    df_clean['Overall Qual_1'], df_clean['Overall Qual_2'] = add_poly('Overall Qual')\n",
    "    df_clean['Exter Qual_1'], df_clean['Exter Qual_2'] = add_poly('Exter Qual')\n",
    "    df_clean['Gr Liv Area_1'], df_clean['Gr Liv Area_2'] = add_poly('Gr Liv Area')\n",
    "    df_clean['Kitchen Qual_1'], df_clean['Kitchen Qual_2'] = add_poly('Kitchen Qual')\n",
    "    df_clean['Total Bsmt SF_1'], df_clean['Total Bsmt SF_2'] = add_poly('Total Bsmt SF')\n",
    "    df_clean['Garage Cars_1'], df_clean['Garage Cars_2'] = add_poly('Garage Cars')\n",
    "    df_clean['Garage Area_1'], df_clean['Garage Area_2'] = add_poly('Garage Area')\n",
    "    df_clean['Total Rooms_1'], df_clean['Total Rooms_2'] = add_poly('Total Rooms')\n",
    "    \n",
    "    # Final check for missing values\n",
    "    print('Dataset has {} entries and {} features.'.format(df_clean.shape[0], df_clean.shape[1]))\n",
    "    print(\"There are\",df_clean.isnull().sum().sum(),\"missing values remaining.\")\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 2426 entries and 111 features.\n",
      "There are 0 missing values remaining.\n"
     ]
    }
   ],
   "source": [
    "df_clean = preprocess_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10bfc3fd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a81f978>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 272,
       "width": 364
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(df_clean['Garage Area_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify variables\n",
    "\n",
    "# 1 - Numeric variables\n",
    "numeric = ['Lot Frontage', 'Lot Area', 'Mas Vnr Area','BsmtFin SF 1','BsmtFin SF 2','Bsmt Unf SF','Total Bsmt SF',\n",
    "           'Total Bsmt SF_1', 'Total Bsmt SF_2', '1st Flr SF','2nd Flr SF','Low Qual Fin SF','Gr Liv Area',\n",
    "           'Gr Liv Area_1', 'Gr Liv Area_2', 'Garage Area', 'Garage Area_1', 'Garage Area_2', \n",
    "           'Wood Deck SF','Open Porch SF', 'Enclosed Porch','3Ssn Porch','Screen Porch','Pool Area','Misc Val',\n",
    "           'Total SF', 'Total SF_1', 'Total SF_2', 'OverallQualxTotalSF', 'OverallQualxTotalSF_1',\n",
    "           'OverallQualxTotalSF_2'\n",
    "          ]\n",
    "# 2 - Categorical variables\n",
    "# 2.1 - Categorical variables, ordinal (possibility of ordering)\n",
    "categorical_ordinal = ['Lot Shape', 'Utilities', 'Land Slope', 'Overall Qual', 'Overall Qual_1', 'Overall Qual_2',\n",
    "                       'Overall Cond', 'Exter Qual', 'Exter Qual_1', 'Exter Qual_2', 'Exter Cond','Bsmt Qual', 'Bsmt Cond',\n",
    "                       'Bsmt Exposure', 'BsmtFin Type 1','BsmtFin Type 2', 'Heating QC','Electrical','Kitchen Qual',\n",
    "                       'Kitchen Qual_1', 'Kitchen Qual_2', 'Functional','Fireplace Qu','Garage Finish','Garage Qual',\n",
    "                       'Garage Cond','Paved Drive','Pool QC','Fence', 'Overall Grade', 'Garage Grade', 'Exter Grade'\n",
    "                      ]\n",
    "# 2.2 - Categorical variables, nominal (no possibility to order) \n",
    "categorical_nominal = ['MS SubClass','MS Zoning','Street', 'Alley', 'Land Contour', 'Lot Config', 'Neighborhood',\n",
    "                      'Condition 1', 'Condition 2', 'Bldg Type','House Style','Roof Style', 'Roof Matl','Exterior 1st',\n",
    "                      'Exterior 2nd','Mas Vnr Type','Foundation','Heating','Central Air','Garage Type','Misc Feature',\n",
    "                       'Sale Type','Sale Condition', 'Remodeled', 'RecentRemodel', 'NewHouse', 'Sale Season'\n",
    "                      ]\n",
    "# 2.3 - Categorical variables, discrete\n",
    "categorical_discrete = ['Year Built', 'Year Remod/Add','Bsmt Full Bath','Bsmt Half Bath','Full Bath','Half Bath',\n",
    "                       'Bedroom AbvGr','Kitchen AbvGr','TotRms AbvGrd','Fireplaces','Garage Yr Blt','Garage Cars',\n",
    "                        'Garage Cars_1', 'Garage Cars_2', 'Mo Sold', 'Yr Sold', 'Total Rooms', 'Total Rooms_1',\n",
    "                        'Total Rooms_2'\n",
    "                       ]\n",
    "categorical = categorical_ordinal + categorical_nominal + categorical_discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Misc Val                 20.885676\n",
       "Pool Area                18.015203\n",
       "Pool QC                  17.390010\n",
       "Lot Area                 13.140634\n",
       "Low Qual Fin SF          12.456269\n",
       "3Ssn Porch               11.903630\n",
       "NewHouse                  5.060548\n",
       "OverallQualxTotalSF_2     4.739869\n",
       "Total Bsmt SF_2           4.487053\n",
       "Garage Area_2             4.425931\n",
       "Kitchen AbvGr             4.374352\n",
       "Enclosed Porch            4.184678\n",
       "BsmtFin SF 2              4.032680\n",
       "Bsmt Half Bath            3.993066\n",
       "Screen Porch              3.773936\n",
       "Gr Liv Area_2             3.429092\n",
       "RecentRemodel             3.195104\n",
       "BsmtFin Type 2            3.092316\n",
       "OverallQualxTotalSF_1     2.756664\n",
       "Total SF_2                2.677789\n",
       "Open Porch SF             2.616856\n",
       "Mas Vnr Area              2.510134\n",
       "Garage Cars_2             2.258333\n",
       "Total Rooms_2             2.159437\n",
       "Total Bsmt SF_1           2.146011\n",
       "Garage Area_1             2.104660\n",
       "Gr Liv Area_1             1.923242\n",
       "Wood Deck SF              1.918250\n",
       "Fence                     1.706178\n",
       "SalePrice                 1.604094\n",
       "Total SF_1                1.595518\n",
       "Exter Qual_2              1.520144\n",
       "MS SubClass               1.377146\n",
       "Overall Qual_2            1.359778\n",
       "Lot Frontage              1.356486\n",
       "Exter Cond                1.342980\n",
       "Total Rooms_1             1.285292\n",
       "Kitchen Qual_2            1.248749\n",
       "OverallQualxTotalSF       1.173100\n",
       "Exter Qual_1              1.124030\n",
       "Garage Cars_1             1.103844\n",
       "Bsmt Exposure             1.091074\n",
       "1st Flr SF                0.935724\n",
       "Bsmt Unf SF               0.928898\n",
       "Kitchen Qual_1            0.846013\n",
       "Gr Liv Area               0.830759\n",
       "2nd Flr SF                0.829521\n",
       "BsmtFin SF 1              0.813868\n",
       "Overall Qual_1            0.806620\n",
       "Exter Grade               0.792116\n",
       "Exter Qual                0.766949\n",
       "Half Bath                 0.761075\n",
       "Fireplaces                0.745431\n",
       "TotRms AbvGrd             0.686209\n",
       "Bsmt Full Bath            0.633668\n",
       "Total SF                  0.615759\n",
       "Total Rooms               0.545288\n",
       "Overall Cond              0.538728\n",
       "Kitchen Qual              0.416707\n",
       "Total Bsmt SF             0.374311\n",
       "Bedroom AbvGr             0.220649\n",
       "Overall Grade             0.198745\n",
       "Mo Sold                   0.197571\n",
       "Garage Area               0.195003\n",
       "Fireplace Qu              0.189699\n",
       "Overall Qual              0.155876\n",
       "Yr Sold                   0.150286\n",
       "Remodeled                 0.145568\n",
       "Garage Finish             0.144849\n",
       "Full Bath                 0.126544\n",
       "LogSalePrice             -0.092830\n",
       "Garage Yr Blt            -0.125066\n",
       "BsmtFin Type 1           -0.152459\n",
       "Garage Cars              -0.279200\n",
       "Year Remod/Add           -0.446840\n",
       "Heating QC               -0.531701\n",
       "Sale Season              -0.565782\n",
       "Year Built               -0.594384\n",
       "Lot Shape                -1.198447\n",
       "Bsmt Qual                -1.304440\n",
       "Garage Grade             -2.471712\n",
       "Paved Drive              -2.932360\n",
       "Garage Qual              -3.186442\n",
       "Garage Cond              -3.304132\n",
       "Bsmt Cond                -3.524445\n",
       "Electrical               -4.254599\n",
       "Land Slope               -5.016785\n",
       "Functional               -5.098566\n",
       "Utilities               -33.489892\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normality tests\n",
    "#check if distribution are normal (heavy tail ?) for continuous variables\n",
    "# stick with kurtosis (high tail?) and skewness analysis\n",
    "df_clean.skew().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric:\n",
    "    plt.figure(figsize=(3,3))\n",
    "    sns.distplot(df_clean[col])\n",
    "    #plt.hist(df_clean[col])\n",
    "    plt.title(col)\n",
    "    plt.show\n",
    "    print(col, \"Skewness: %f\" % data[col].skew())\n",
    "    print(col, \"Kurtosis: %f\" % data[col].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skewed numerical features to log transform: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Misc Val</th>\n",
       "      <td>20.872760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pool Area</th>\n",
       "      <td>18.004062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lot Area</th>\n",
       "      <td>13.132508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low Qual Fin SF</th>\n",
       "      <td>12.448565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3Ssn Porch</th>\n",
       "      <td>11.896268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQualxTotalSF_2</th>\n",
       "      <td>4.736937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Bsmt SF_2</th>\n",
       "      <td>4.484278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Area_2</th>\n",
       "      <td>4.423194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enclosed Porch</th>\n",
       "      <td>4.182091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFin SF 2</th>\n",
       "      <td>4.030186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Screen Porch</th>\n",
       "      <td>3.771602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gr Liv Area_2</th>\n",
       "      <td>3.426971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQualxTotalSF_1</th>\n",
       "      <td>2.754960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total SF_2</th>\n",
       "      <td>2.676133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open Porch SF</th>\n",
       "      <td>2.615238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <td>2.508582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Bsmt SF_1</th>\n",
       "      <td>2.144684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Area_1</th>\n",
       "      <td>2.103359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gr Liv Area_1</th>\n",
       "      <td>1.922053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wood Deck SF</th>\n",
       "      <td>1.917063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total SF_1</th>\n",
       "      <td>1.594532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lot Frontage</th>\n",
       "      <td>1.355648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQualxTotalSF</th>\n",
       "      <td>1.172375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st Flr SF</th>\n",
       "      <td>0.935146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Unf SF</th>\n",
       "      <td>0.928323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <td>0.830245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd Flr SF</th>\n",
       "      <td>0.829008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFin SF 1</th>\n",
       "      <td>0.813365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Skew\n",
       "Misc Val               20.872760\n",
       "Pool Area              18.004062\n",
       "Lot Area               13.132508\n",
       "Low Qual Fin SF        12.448565\n",
       "3Ssn Porch             11.896268\n",
       "OverallQualxTotalSF_2   4.736937\n",
       "Total Bsmt SF_2         4.484278\n",
       "Garage Area_2           4.423194\n",
       "Enclosed Porch          4.182091\n",
       "BsmtFin SF 2            4.030186\n",
       "Screen Porch            3.771602\n",
       "Gr Liv Area_2           3.426971\n",
       "OverallQualxTotalSF_1   2.754960\n",
       "Total SF_2              2.676133\n",
       "Open Porch SF           2.615238\n",
       "Mas Vnr Area            2.508582\n",
       "Total Bsmt SF_1         2.144684\n",
       "Garage Area_1           2.103359\n",
       "Gr Liv Area_1           1.922053\n",
       "Wood Deck SF            1.917063\n",
       "Total SF_1              1.594532\n",
       "Lot Frontage            1.355648\n",
       "OverallQualxTotalSF     1.172375\n",
       "1st Flr SF              0.935146\n",
       "Bsmt Unf SF             0.928323\n",
       "Gr Liv Area             0.830245\n",
       "2nd Flr SF              0.829008\n",
       "BsmtFin SF 1            0.813365"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform all the skewed feature by taking log ?\n",
    "# skew > 0,75 , considered as moderately to highly skewed\n",
    "# This will make the features more normal.\n",
    "\n",
    "# To do after encoding but BEFORE OHE\n",
    "# TO DO : compléter liste 'numeric' des features crées \n",
    "# Check the skewness of numerical features\n",
    "numeric_features = pd.Index(numeric)\n",
    "\n",
    "skewed_features = df_clean[numeric_features].apply(lambda x: skew(x.dropna()))\n",
    "skewed_features = skewed_features[abs(skewed_features) > 0.75]\n",
    "print(\"\\nSkewed numerical features to log transform: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_features})\n",
    "skewness.sort_values(by='Skew', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 skewed numerical features to log transform\n"
     ]
    }
   ],
   "source": [
    "# Log transform of the skewed numerical features \n",
    "# As a general rule of thumb, a skewness with an absolute value > 0.5 is considered at least moderately skewed\n",
    "\n",
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(str(skewness.shape[0]) + \" skewed numerical features to log transform\")\n",
    "skewed_features = skewness.index\n",
    "df_clean[skewed_features] = np.log1p(df_clean[skewed_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lot Frontage             -1.070485\n",
       "Lot Area                 -0.448306\n",
       "Mas Vnr Area              0.487983\n",
       "BsmtFin SF 1             -0.616978\n",
       "BsmtFin SF 2              2.430884\n",
       "Bsmt Unf SF              -2.106542\n",
       "Total Bsmt SF_1          -4.822196\n",
       "Total Bsmt SF_2          -4.822194\n",
       "1st Flr SF               -0.023496\n",
       "2nd Flr SF                0.334585\n",
       "Low Qual Fin SF           9.017904\n",
       "Gr Liv Area              -0.099839\n",
       "Gr Liv Area_1            -0.100610\n",
       "Gr Liv Area_2            -0.100612\n",
       "Garage Area_1            -3.443634\n",
       "Garage Area_2            -3.443629\n",
       "Wood Deck SF              0.169100\n",
       "Open Porch SF            -0.043779\n",
       "Enclosed Porch            1.986274\n",
       "3Ssn Porch                9.123319\n",
       "Screen Porch              2.900091\n",
       "Pool Area                15.630145\n",
       "Misc Val                  5.153962\n",
       "Total SF_1               -0.538233\n",
       "Total SF_2               -0.538234\n",
       "OverallQualxTotalSF      -0.730520\n",
       "OverallQualxTotalSF_1    -0.731166\n",
       "OverallQualxTotalSF_2    -0.731166\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare before and after log transform\n",
    "df_clean[skewed_features].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data ? see in EPFL course\n",
    "# Additional processing: scale the data.   \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_df_munged[numeric_features])\n",
    "\n",
    "scaled = scaler.transform(train_df_munged[numeric_features])\n",
    "for i, col in enumerate(numeric_features):\n",
    "    train_df_munged[col] = scaled[:, i]\n",
    "\n",
    "scaled = scaler.transform(test_df_munged[numeric_features])\n",
    "for i, col in enumerate(numeric_features):\n",
    "    test_df_munged[col] = scaled[:, i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find outliers:\n",
    "# plot of SALE PRICE versus GR LIV AREA \n",
    "plt.Figure(figsize=(8,8))\n",
    "plt.scatter(data['SalePrice'], data['Gr Liv Area'] );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove very large houses (more than 4000 square feet) (this is included in the preprocessing function)\n",
    "#df_clean = df_clean[df_clean['Gr Liv Area'] < 4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impact of removing theses 4 outliers\n",
    "a = df_clean['Gr Liv Area'].describe() - data['Gr Liv Area'].describe()\n",
    "print(a)\n",
    "plt.Figure(figsize=(8,8))\n",
    "plt.scatter(df_clean['SalePrice'], df_clean['Gr Liv Area']  );\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "## 2. Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode df\n",
    "\n",
    "def encode(df):\n",
    "    df_encoded = df.copy()\n",
    "    \n",
    "    # One-hot encoding for nominal variables \n",
    "    df_encoded = pd.get_dummies(df_encoded, columns=categorical_nominal)\n",
    "    \n",
    "    print('Origina Size:', df.shape, 'Size when encoded:', df_encoded.shape)\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origina Size: (2426, 111) Size when encoded: (2426, 278)\n"
     ]
    }
   ],
   "source": [
    "df_encoded = encode(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TO CHECK : #### Test vs train sets ####\n",
    "\n",
    "# These onehot columns are missing in the test data, so drop them from the\n",
    "# training data or we might overfit on them.\n",
    "drop_cols = [\n",
    "                \"_Exterior1st_ImStucc\", \"_Exterior1st_Stone\",\n",
    "                \"_Exterior2nd_Other\",\"_HouseStyle_2.5Fin\", \n",
    "            \n",
    "                \"_RoofMatl_Membran\", \"_RoofMatl_Metal\", \"_RoofMatl_Roll\",\n",
    "                \"_Condition2_RRAe\", \"_Condition2_RRAn\", \"_Condition2_RRNn\",\n",
    "                \"_Heating_Floor\", \"_Heating_OthW\",\n",
    "\n",
    "                \"_Electrical_Mix\", \n",
    "                \"_MiscFeature_TenC\",\n",
    "                \"_GarageQual_Ex\", \"_PoolQC_Fa\"\n",
    "            ]\n",
    "            ]\n",
    "#train_df.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# This column is missing in the training data. There is only one example with\n",
    "# this value in the test set. So just drop it.\n",
    "test_df.drop([\"_MSSubClass_150\"], axis=1, inplace=True)\n",
    "\n",
    "# Drop these columns. They are either not very helpful or they cause overfitting.\n",
    "drop_cols = [\n",
    "    \"_Condition2_PosN\",    # only two are not zero\n",
    "    \"_MSZoning_C (all)\",\n",
    "    \"_MSSubClass_160\",\n",
    "]\n",
    "train_df.drop(drop_cols, axis=1, inplace=True)\n",
    "test_df.drop(drop_cols, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regarding Label Encoder:\n",
    "# after Fred 1-on-1 : \n",
    "# déconseille d'utiliser Laberl encoder,\n",
    "# ratio datapoints vs. nombre colonnes : 10%\n",
    "# va créer une 'relation' ! (qui n'existe pas)\n",
    "\n",
    "##### Here is my problem: #####\n",
    "\n",
    "#2. Label Encoding categorical nominal variables with sklearn LabelEncoder \n",
    "#Labeling with scikit learn (instead of OHE) the categorical_nominal features in order to reduce dimensionality\n",
    "#for cat ORDINAL, the order is not the same, so I stick to the .replace method\n",
    "\n",
    "# import preprocessing from sklearn\n",
    "from sklearn import preprocessing\n",
    "# Create a LabelEncoder object and fit it to each feature in test DF\n",
    "le = preprocessing.LabelEncoder()\n",
    "# use df.apply() to apply le.fit_transform to categorical_nominal features\n",
    "\n",
    "df_le = df_clean.copy()\n",
    "#df_le[categorical_ordinal].apply(le.fit_transform) #not working ?\n",
    "\n",
    "#df_le = df_clean[categorical_nominal].apply(le.fit_transform) # works but has only the transformed columns\n",
    "\n",
    "print('Origina Size:', df_clean.shape)\n",
    "print('Size when Label encoded:', df_le.shape)\n",
    "\n",
    "#I don't understand why the following works, ie. returne the labeled columns\n",
    "df_le[categorical_ordinal].apply(le.fit_transform).head()\n",
    "\n",
    "# but this doesn't return the labeled columns ?\n",
    "df_le[categorical_ordinal] = df_le[categorical_ordinal].apply(le.fit_transform)\n",
    "df_le[categorical_nominal].head()\n",
    "\n",
    "#and this doesn't work neither : \n",
    "df_le.apply(le.fit_transform(df_clean[categorical_nominal]))\n",
    "\n",
    "# It works with a sklearn pipeline, although it's not my code & I did not yet looked further into pipelines\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)\n",
    "\n",
    "# I want to encode only the categorical_nominal features, while leaving the other features untransformed.\n",
    "#df_le = MultiColumnLabelEncoder(columns = categorical_nominal).fit_transform(df_clean)\n",
    "#df_le.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a closer look at the target variable: before removing outliers, skewed distribution\n",
    "sns.distplot(data['SalePrice']);\n",
    "print(\"Skewness: %f\" % data['SalePrice'].skew())\n",
    "print(\"Kurtosis: %f\" % data['SalePrice'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#After removing outliers, reduces skewness a bit\n",
    "sns.distplot(df_clean['SalePrice']);\n",
    "print(\"Skewness: %f\" % df_clean['SalePrice'].skew())\n",
    "print(\"Kurtosis: %f\" % df_clean['SalePrice'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a LogSalePrice variable to the DataFrame (this is included in the preprocessing function)\n",
    "#df_clean['LogSalePrice'] = np.log10(df_clean['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of the log10 of SalePrice :, skewness reduced\n",
    "sns.distplot(df_clean['LogSalePrice']);\n",
    "print(\"Skewness: %f\" % df_clean['LogSalePrice'].skew())\n",
    "print(\"Kurtosis: %f\" % df_clean['LogSalePrice'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Total surface count\n",
    "#df_clean['TotalSF'] = df_clean['Total Bsmt SF'] + df_clean['Gr Liv Area']\n",
    "print(df_clean['Total SF'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Total count of rooms\n",
    "#df_clean['Total_rooms'] = (df_clean['TotRms AbvGrd'] + df_clean[''Bsmt Full Bath'] + \n",
    "#                                df_clean['Bsmt Half Bath'] + df_clean['Full Bath'] + df_clean['Half Bath']) \n",
    "\n",
    "total_rooms = ['TotRms AbvGrd', 'Bsmt Full Bath', 'Bsmt Half Bath', 'Full Bath', 'Half Bath']\n",
    "print(df_clean[total_rooms].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicator variables (year of construction is older than some threshold)\n",
    "# Built before 1980 & no remodeling \n",
    "# df_clean['Built/Re bef 80'] = (df_clean['Year Remod/Add'] >1980)*1\n",
    "\n",
    "sns.distplot(df_clean['Year Remod/Add']);\n",
    "print(df_clean['Year Remod/Add'].describe())\n",
    "\n",
    "# or just add a 'Remodeled' feature :\n",
    "# If YearRemodAdd != YearBuilt, then a remodeling took place at some point.\n",
    "# df_clean[\"Remodeled\"] = (df_clean[\"Year Remod/Add\"] != df_clean[\"Year Built\"]) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a seasonality feature\n",
    "\n",
    "#visual rerpresentation of sales per given month\n",
    "grp = df_clean.groupby(['Yr Sold','Mo Sold'])\n",
    "piv = grp.count()['SalePrice'].reset_index()\n",
    "piv.columns = ['Overall Qual','Mo Sold','SalePrice']\n",
    "sns.pointplot(x='Mo Sold', y='SalePrice', hue='Overall Qual', data=piv, join=True)\n",
    "plt.legend(loc='best', bbox_to_anchor=(1.05, 0.8, 0.2, 0));\n",
    "\n",
    "#create a feature with a 'high season' and 'low season'\n",
    "#df_clean['SaleSeason'] = df_clean['Mo Sold'].replace({1:0, 2:0, 3:0, 4:1, 5:1, 6:1, 7:1, 8:1, 9:0, 10:0, 11:0, 12:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of a composite feature : TotalSF * Overall Quality:\n",
    "# df_clean['OverallQualxTotalSF'] = df_clean['TotalSF'] * df_clean['Overall Qual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add polynomial features for the 10 most correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove atypical sales (foreclosure...)\n",
    "df_encoded['Sale Condition_Abnorml'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Univariate feature selection\n",
    "Univariate feature selection examines each feature individually to determine the strength of the relationship of the feature with the response variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Pearson correlation coef\n",
    "One of the simplest method for understanding a feature’s relation to the response variable is Pearson correlation coefficient, which measures linear correlation between two variables. The resulting value lies in [-1;1]\n",
    "\n",
    "__Works good when linear relation between feature and target__\n",
    "\n",
    "There are at least two reasons why to prefer Pearson correlation over more sophisticated methods such as MIC or distance correlation when the relationship is close to linear. For one, computing the Pearson correlation is much faster, which may be important in case of big datasets. Secondly, the range of the correlation coefficient is [-1;1] (instead of [0;1] for MIC and distance correlation). This can relay useful extra information on whether the relationship is negative or positive, i.e. do higher feature values imply higher values of the response variables or vice versa. But of course the question of negative versus positive correlation is only well-posed if the relationship between the two variables is monotonic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FRED:\n",
    "\n",
    "# p value : corrélation due au hasard ?\n",
    "# p value < 5% \n",
    "# cf. intro to stat learning\n",
    "#éventuellement utiliser sklearn feature selection http://scikit-learn.org/stable/modules/feature_selection.html\n",
    "#pearson correl : soit très corrélée soit -1\n",
    "#approche quant (ce cours) vs. qual\n",
    "\n",
    "# collinear variables: what to do with highly collinear variables ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most correlated features in abs value\n",
    "corr = df_clean.corr()\n",
    "corr_abs = corr['SalePrice'].abs().sort_values(ascending=False)\n",
    "print(corr_abs[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is correl after OHE\n",
    "corr = df_encoded.corr()\n",
    "corr.sort_values([\"SalePrice\"], ascending = False, inplace = True)\n",
    "print(corr.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__better method :__ \n",
    " Scipy‘s pearsonr method computes both the correlation and p-value for the correlation, roughly showing the probability of an uncorrelated system creating a correlation value of this magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same corr matrix but presented graphically:\n",
    "corrmat = data.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we detect highly collinear variables in the heatmap (light squares) :\n",
    "# Total Bsmt SF & 1st Floor SF\n",
    "# Garage features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most correlated features\n",
    "corrmat = df_clean.corr()\n",
    "top_corr_features = corrmat.index[abs(corrmat[\"SalePrice\"])>0.5]\n",
    "plt.figure(figsize=(10,10))\n",
    "g = sns.heatmap(df_clean[top_corr_features].corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error on this graph ??\n",
    "# heatmap zoomed on Sale Price\n",
    "k = 10 #number of variables for heatmap\n",
    "cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "cm = np.corrcoef(data[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus on year built : onlys slightly correlated\n",
    "#'OverallQual', 'GrLivArea' and 'TotalBsmtSF' are strongly correlated with 'SalePrice'. \n",
    "# garage : only pick one\n",
    "# 'TotalBsmtSF' and '1stFloor': only pick one\n",
    "#'TotRmsAbvGrd' and 'GrLivArea', only pick one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['SalePrice', 'Garage Cars', 'Garage Area']\n",
    "corr = data[cols].corr()\n",
    "corr.sort_values([\"SalePrice\"], ascending = False, inplace = True)\n",
    "print(corr.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols = ['Garage Cars', 'Garage Area']\n",
    "corr = data[cols].corr()\n",
    "corr.sort_values(['Garage Cars'], ascending = False, inplace = True)\n",
    "print(corr['Garage Cars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now, plot the data\n",
    "__relying only on the correlation value on interpreting the relationship of two variables can be highly misleading, so it is always worth plotting the data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter plot grlivarea/saleprice\n",
    "var = 'Gr Liv Area'\n",
    "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter plot totalbsmtsf/saleprice\n",
    "var = 'Total Bsmt SF'\n",
    "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relationship with categorical features\n",
    "#box plot overallqual/saleprice\n",
    "var = 'Overall Qual'\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'Year Built'\n",
    "f, ax = plt.subplots(figsize=(16, 8))\n",
    "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000);\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection : conclusion\n",
    "GrLivArea' and 'TotalBsmtSF' seem to be linearly related with 'SalePrice'. Both relationships are positive, which means that as one variable increases, the other also increases. In the case of 'TotalBsmtSF', we can see that the slope of the linear relationship is particularly high.\n",
    "'OverallQual' and 'YearBuilt' also seem to be related with 'SalePrice'. The relationship seems to be stronger in the case of 'OverallQual', where the box plot shows how sales prices increase with the overall quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "### 5. Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then create and evaluate different models. Split the data into train and test sets (50-50 split). Fit your model using the train set and evaluate it using the test one. Your analysis should include the following models.\n",
    "\n",
    "A \"simple\" model with two variables (three with the target variable)\n",
    "An \"intermediate\" model (between 10 and 20 variables).\n",
    "A \"complex model\" with all variables.\n",
    "Count the number of variables before applying one-hot encoding. Also, these variables can be combinations of other variables. For instance, the author of the data set suggests fitting a model using the total surface and the sale condition. This model has a total of two variables even if the total surface is itself a combination of two variables (basement + above grade surfaces) and encoding the sale condition variable with one-hot encoding leads to the creation of 6 dummy variables.\n",
    "\n",
    "Try adding regularization (i.e., Ridge regression) for the intermediate and complex models. Tune the regularization strength using grid search.\n",
    "\n",
    "Important: Remember to use the logarithm of the sale prices to fit your models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame: (1213, 278)\n",
      "Test DataFrame: (1213, 278)\n"
     ]
    }
   ],
   "source": [
    "# Split into train/test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df_encoded, train_size=0.5, test_size=0.5, random_state=0)\n",
    "\n",
    "print('Train DataFrame:', train_df.shape)\n",
    "print('Test DataFrame:', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define error metric : \n",
    "# Root mean squared error\n",
    "def RMSE(y, y_pred):\n",
    "    mse = np.mean(np.square(y - y_pred)) \n",
    "    return np.sqrt(mse) \n",
    "\n",
    "# Mean absolute error\n",
    "def MAE(y, y_pred):\n",
    "    return np.mean(np.abs(y - y_pred))    \n",
    "\n",
    "# function to create feature list from selected features\n",
    "def create_features(feature_list):\n",
    "    features = []\n",
    "    for feature in feature_list:\n",
    "        features.extend(df_encoded.filter(like=feature).columns.tolist())\n",
    "    print('Selected features:', features)\n",
    "    return features\n",
    "\n",
    "# Function to create variables\n",
    "def create_variables(features, target):\n",
    "    X_tr, y_tr, X_te, y_te = None, None, None, None  # is it worth doing this ? Variables inside a function are 'new'??\n",
    "    X_tr = train_df[features].values\n",
    "    y_tr = train_df[target].values\n",
    "    X_te = test_df[features].values \n",
    "    y_te = test_df[target].values\n",
    "    print('X_tr shape:', X_tr.shape, 'y_tr shape:', y_tr.shape,'X_te shape:', X_te.shape, 'y_te shape:', y_te.shape)\n",
    "    return X_tr, y_tr, X_te, y_te\n",
    "\n",
    "# Function to fit a linear regression\n",
    "from sklearn.linear_model import LinearRegression, HuberRegressor\n",
    "\n",
    "def fit_lr(X_train, y_train, X_test):\n",
    "    # Create a linear regression\n",
    "    lr = LinearRegression()\n",
    "    \n",
    "    # Fit it to train data\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    # Compute predictions for test set\n",
    "    y_pred = lr.predict(X_test)\n",
    "    #print(\"Linear regression coefficients:\",lr.coef_)\n",
    "    return y_pred\n",
    "\n",
    "# Function to fit Huber loss\n",
    "def fit_hl(X_train, y_train, X_test):\n",
    "    huber = HuberRegressor(epsilon=1.45)\n",
    "    huber.fit(X_train, y_train) # Fit to train data\n",
    "    y_pred = huber.predict(X_test) #compute predictions for test set\n",
    "    return y_pred\n",
    "\n",
    "# Function to fit Ridge regression\n",
    "from sklearn.linear_model import Ridge\n",
    "def fit_ridge(X_train, y_train, X_test):\n",
    "    ridge = Ridge(alpha=1e-4)  #setting a lower alpha value\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred = ridge.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit Ridge regression\n",
    "from sklearn.linear_model import Ridge\n",
    "def fit_ridge(X_train, y_train, X_test):\n",
    "    ridge = Ridge(alpha=1e-4)  #setting a lower alpha value\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred = ridge.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing grid search for Ridge regression\n",
    "def grid_search(X_train, y_train):   #which inputs?\n",
    "    \n",
    "# Define a set of alpha values\n",
    "    alphas = np.logspace(-10, 0, num=100)\n",
    "\n",
    "# Save train/test scores\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "\n",
    "# Grid search\n",
    "    for alpha in alphas:\n",
    "    # Ridge regression\n",
    "        ridge = Ridge(alpha)\n",
    "        ridge.fit(X_train, y_train)\n",
    "    \n",
    "    # Train score\n",
    "        y_pred = ridge.predict(X_tr)\n",
    "        train_scores.append(mse(y_tr, y_pred))\n",
    "    \n",
    "    # Test score\n",
    "        y_pred = ridge.predict(X_te)\n",
    "        test_scores.append(mse(y_te, y_pred))\n",
    "    \n",
    "# Find best alpha\n",
    "    idx = np.argmin(test_scores)\n",
    "    best_alpha = alphas[idx]\n",
    "    print('Best alpha {:.1e}'.format(best_alpha))\n",
    "\n",
    "# Print train/test scores\n",
    "print('Ridge regression 2 - MSE train: {:,.0f} test: {:,.0f}'.format(\n",
    "    train_scores[idx],\n",
    "    test_scores[idx]\n",
    "))\n",
    "\n",
    "# Ridge regression with tuned alpha\n",
    "    ridge2 = Ridge(best_alpha)\n",
    "    return ridge2.fit(X_tr, y_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['OverallQualxTotalSF', 'OverallQualxTotalSF_1', 'OverallQualxTotalSF_2', 'Exter Grade']\n",
      "X_tr shape: (1213, 4) y_tr shape: (1213,) X_te shape: (1213, 4) y_te shape: (1213,)\n",
      "Best alpha 2.2e-06\n",
      "Ridge regression 2 - MSE train: 0 test: 0\n"
     ]
    }
   ],
   "source": [
    "features = create_features(['OverallQualxTotalSF', 'Exter Grade'])\n",
    "\n",
    "# Create X/y variables\n",
    "X_tr, y_tr, X_te, y_te = create_variables(features, 'LogSalePrice')\n",
    "\n",
    "# Define a set of alpha values\n",
    "alphas = np.logspace(-10, 0, num=100)\n",
    "\n",
    "# Save train/test scores\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "#grid search\n",
    "for alpha in alphas:\n",
    "    # Ridge regression\n",
    "    ridge = Ridge(alpha)\n",
    "    ridge.fit(X_tr, y_tr)\n",
    "    \n",
    "    # Train score\n",
    "    y_pred = ridge.predict(X_tr)\n",
    "    train_scores.append(RMSE(y_tr, y_pred))\n",
    "    \n",
    "    # Test score\n",
    "    y_pred = ridge.predict(X_te)\n",
    "    test_scores.append(RMSE(y_te, y_pred))\n",
    "    \n",
    "# Find best alpha\n",
    "idx = np.argmin(test_scores)\n",
    "best_alpha = alphas[idx]\n",
    "print('Best alpha {:.1e}'.format(best_alpha))\n",
    "\n",
    "# Print train/test scores\n",
    "print('Ridge regression 2 - MSE train: {:,.0f} test: {:,.0f}'.format(\n",
    "    train_scores[idx],\n",
    "    test_scores[idx]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=2.2051307399030456e-06, copy_X=True, fit_intercept=True,\n",
       "   max_iter=None, normalize=False, random_state=None, solver='auto',\n",
       "   tol=0.001)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge regression with tuned alpha\n",
    "ridge2 = Ridge(best_alpha)\n",
    "ridge2.fit(X_tr, y_tr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Simple\" model with two variables (three with the target variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['Overall Qual', 'Overall Qual_1', 'Overall Qual_2', 'Gr Liv Area', 'Gr Liv Area_1', 'Gr Liv Area_2']\n",
      "X_tr shape: (1213, 6) y_tr shape: (1213,) X_te shape: (1213, 6) y_te shape: (1213,)\n",
      "RMSE baseline: 0.178\n",
      "MAE baseline: 54125.121\n",
      "RMSE linear regression on TRAIN set: 0.225\n",
      "RMSE linear regression: 0.089\n",
      "MAE linear regression: 24579.950\n",
      "RMSE Ridge on TRAIN set: 0.225\n",
      "RMSE Ridge: 0.089\n",
      "MAE Ridge: 24632.362\n"
     ]
    }
   ],
   "source": [
    "# Select features\n",
    "features = create_features(['Overall Qual', 'Gr Liv Area'])\n",
    "\n",
    "# Create X/y variables\n",
    "X_tr, y_tr, X_te, y_te = create_variables(features, 'LogSalePrice')\n",
    "\n",
    "# Median baseline\n",
    "rmse_baseline = RMSE(y_te, np.median(y_te))\n",
    "mae_baseline = MAE(10**y_te, np.median(10**y_te))\n",
    "\n",
    "print('RMSE baseline: {:.3f}'.format(rmse_baseline))\n",
    "print('MAE baseline: {:.3f}'.format(mae_baseline))\n",
    "\n",
    "# Linear regression\n",
    "y_pred = fit_lr(X_tr, y_tr, X_te)\n",
    "rmse_lr = RMSE(y_te, y_pred)\n",
    "mae_lr = MAE(10**y_te, 10**y_pred)\n",
    "rmse_lr_TRAIN = RMSE(y_tr, y_pred)\n",
    "print('RMSE linear regression on TRAIN set: {:.3f}'.format(rmse_lr_TRAIN))\n",
    "print('RMSE linear regression: {:.3f}'.format(rmse_lr))\n",
    "print('MAE linear regression: {:.3f}'.format(mae_lr))\n",
    "\n",
    "#Ridge regression\n",
    "y_pred = fit_ridge(X_tr, y_tr, X_te)\n",
    "rmse_ridge = RMSE(y_te, y_pred)\n",
    "mae_ridge = MAE(10**y_te, 10**y_pred)\n",
    "rmse_ridge_TRAIN = RMSE(y_tr, y_pred)\n",
    "print('RMSE Ridge on TRAIN set: {:.3f}'.format(rmse_ridge_TRAIN))\n",
    "print('RMSE Ridge: {:.3f}'.format(rmse_ridge))\n",
    "print('MAE Ridge: {:.3f}'.format(mae_ridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Simple\" model with two variables (three with the target variable) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['OverallQualxTotalSF', 'OverallQualxTotalSF_1', 'OverallQualxTotalSF_2', 'Exter Grade']\n",
      "X_tr shape: (1213, 4) y_tr shape: (1213,) X_te shape: (1213, 4) y_te shape: (1213,)\n",
      "RMSE baseline: 0.178\n",
      "MAE baseline: 54125.121\n",
      "\n",
      "\n",
      "RMSE linear regression on TRAIN set: 0.345\n",
      "RMSE linear regression: 0.253\n",
      "MAE linear regression: 21079.664\n",
      "\n",
      "\n",
      "RMSE Ridge on TRAIN set: 0.232\n",
      "RMSE Ridge: 0.082\n",
      "MAE Ridge: 21966.993\n"
     ]
    }
   ],
   "source": [
    "features = create_features(['OverallQualxTotalSF', 'Exter Grade'])\n",
    "\n",
    "# Create X/y variables\n",
    "X_tr, y_tr, X_te, y_te = create_variables(features, 'LogSalePrice')\n",
    "\n",
    "# Median baseline\n",
    "rmse_baseline = RMSE(y_te, np.median(y_te))\n",
    "mae_baseline = MAE(10**y_te, np.median(10**y_te))\n",
    "\n",
    "print('RMSE baseline: {:.3f}'.format(rmse_baseline))\n",
    "print('MAE baseline: {:.3f}'.format(mae_baseline))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Linear regression\n",
    "y_pred = fit_lr(X_tr, y_tr, X_te)\n",
    "rmse_lr = RMSE(y_te, y_pred)\n",
    "mae_lr = MAE(10**y_te, 10**y_pred)\n",
    "rmse_lr_TRAIN = RMSE(y_tr, y_pred)\n",
    "print('RMSE linear regression on TRAIN set: {:.3f}'.format(rmse_lr_TRAIN))\n",
    "print('RMSE linear regression: {:.3f}'.format(rmse_lr))\n",
    "print('MAE linear regression: {:.3f}'.format(mae_lr))\n",
    "print(\"\\n\")\n",
    "#Ridge regression\n",
    "y_pred = fit_ridge(X_tr, y_tr, X_te)\n",
    "rmse_ridge = RMSE(y_te, y_pred)\n",
    "mae_ridge = MAE(10**y_te, 10**y_pred)\n",
    "rmse_ridge_TRAIN = RMSE(y_tr, y_pred)\n",
    "print('RMSE Ridge on TRAIN set: {:.3f}'.format(rmse_ridge_TRAIN))\n",
    "print('RMSE Ridge: {:.3f}'.format(rmse_ridge))\n",
    "print('MAE Ridge: {:.3f}'.format(mae_ridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Simple\" model with two variables (three with the target variable) - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['OverallQualxTotalSF', 'OverallQualxTotalSF_1', 'OverallQualxTotalSF_2', 'Sale Condition_Abnorml', 'Sale Condition_AdjLand', 'Sale Condition_Alloca', 'Sale Condition_Family', 'Sale Condition_Normal', 'Sale Condition_Partial']\n",
      "X_tr shape: (1213, 9) y_tr shape: (1213,) X_te shape: (1213, 9) y_te shape: (1213,)\n",
      "RMSE baseline: 0.178\n",
      "MAE baseline: 54125.121\n",
      "RMSE linear regression on TRAIN set: 0.380\n",
      "RMSE linear regression: 0.298\n",
      "MAE linear regression: 20993.308\n"
     ]
    }
   ],
   "source": [
    "features = create_features(['OverallQualxTotalSF', 'Sale Cond'])\n",
    "\n",
    "# Create X/y variables\n",
    "X_tr, y_tr, X_te, y_te = create_variables(features, 'LogSalePrice')\n",
    "\n",
    "# Median baseline\n",
    "rmse_baseline = RMSE(y_te, np.median(y_te))\n",
    "mae_baseline = MAE(10**y_te, np.median(10**y_te))\n",
    "\n",
    "print('RMSE baseline: {:.3f}'.format(rmse_baseline))\n",
    "print('MAE baseline: {:.3f}'.format(mae_baseline))\n",
    "\n",
    "# Linear regression\n",
    "y_pred = fit_lr(X_tr, y_tr, X_te)\n",
    "rmse_lr = RMSE(y_te, y_pred)\n",
    "mae_lr = MAE(10**y_te, 10**y_pred)\n",
    "rmse_lr_TRAIN = RMSE(y_tr, y_pred)\n",
    "print('RMSE linear regression on TRAIN set: {:.3f}'.format(rmse_lr_TRAIN))\n",
    "print('RMSE linear regression: {:.3f}'.format(rmse_lr))\n",
    "print('MAE linear regression: {:.3f}'.format(mae_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intermediate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['OverallQualxTotalSF', 'OverallQualxTotalSF_1', 'OverallQualxTotalSF_2', 'Exter Qual', 'Exter Qual_1', 'Exter Qual_2', 'Total SF', 'Total SF_1', 'Total SF_2', 'Overall Qual', 'Overall Qual_1', 'Overall Qual_2', 'Gr Liv Area', 'Gr Liv Area_1', 'Gr Liv Area_2', 'Garage Yr Blt', 'Garage Finish', 'Garage Cars', 'Garage Area', 'Garage Qual', 'Garage Cond', 'Garage Grade', 'Garage Cars_1', 'Garage Cars_2', 'Garage Area_1', 'Garage Area_2', 'Garage Type_2Types', 'Garage Type_Attchd', 'Garage Type_Basment', 'Garage Type_BuiltIn', 'Garage Type_CarPort', 'Garage Type_Detchd', 'Garage Type_NA', 'Neighborhood_Blmngtn', 'Neighborhood_Blueste', 'Neighborhood_BrDale', 'Neighborhood_BrkSide', 'Neighborhood_ClearCr', 'Neighborhood_CollgCr', 'Neighborhood_Crawfor', 'Neighborhood_Edwards', 'Neighborhood_Gilbert', 'Neighborhood_Greens', 'Neighborhood_GrnHill', 'Neighborhood_IDOTRR', 'Neighborhood_Landmrk', 'Neighborhood_MeadowV', 'Neighborhood_Mitchel', 'Neighborhood_NAmes', 'Neighborhood_NPkVill', 'Neighborhood_NWAmes', 'Neighborhood_NoRidge', 'Neighborhood_NridgHt', 'Neighborhood_OldTown', 'Neighborhood_SWISU', 'Neighborhood_Sawyer', 'Neighborhood_SawyerW', 'Neighborhood_Somerst', 'Neighborhood_StoneBr', 'Neighborhood_Timber', 'Neighborhood_Veenker', 'Remodeled_0', 'Remodeled_1', 'RecentRemodel_0', 'RecentRemodel_1', 'NewHouse_0', 'NewHouse_1', 'Sale Season_0', 'Sale Season_1']\n",
      "X_tr shape: (1213, 69) y_tr shape: (1213,) X_te shape: (1213, 69) y_te shape: (1213,)\n",
      "RMSE baseline: 0.178\n",
      "MAE baseline: 54125.121\n",
      "RMSE linear regression on TRAIN set: 0.235\n",
      "RMSE linear regression: 0.074\n",
      "MAE linear regression: 17014.916\n"
     ]
    }
   ],
   "source": [
    "features = create_features(['OverallQualxTotalSF', 'Exter Qual', 'Total SF', 'Overall Qual', 'Gr Liv Area',\n",
    "                            'Garage', 'Neighborhood', 'Remodeled', 'RecentRemodel', 'NewHouse', 'Sale Season'])\n",
    "\n",
    "# Create X/y variables\n",
    "X_tr, y_tr, X_te, y_te = create_variables(features, 'LogSalePrice')\n",
    "\n",
    "# Median baseline\n",
    "rmse_baseline = RMSE(y_te, np.median(y_te))\n",
    "mae_baseline = MAE(10**y_te, np.median(10**y_te))\n",
    "\n",
    "print('RMSE baseline: {:.3f}'.format(rmse_baseline))\n",
    "print('MAE baseline: {:.3f}'.format(mae_baseline))\n",
    "\n",
    "# Linear regression\n",
    "y_pred = fit_lr(X_tr, y_tr, X_te)\n",
    "rmse_lr = RMSE(y_te, y_pred)\n",
    "mae_lr = MAE(10**y_te, 10**y_pred)\n",
    "rmse_lr_TRAIN = RMSE(y_tr, y_pred)\n",
    "print('RMSE linear regression on TRAIN set: {:.3f}'.format(rmse_lr_TRAIN))\n",
    "print('RMSE linear regression: {:.3f}'.format(rmse_lr))\n",
    "print('MAE linear regression: {:.3f}'.format(mae_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr shape: (1213, 276) y_tr shape: (1213,) X_te shape: (1213, 276) y_te shape: (1213,)\n",
      "RMSE linear regression on TRAIN set: 0.338\n",
      "RMSE linear regression: 0.265\n",
      "RMSE Huber Loss: 0.241\n",
      "MAE linear regression: 5955066502.027\n",
      "MAE Huber Loss: 88168.693\n"
     ]
    }
   ],
   "source": [
    "# Fitting a model with all the features\n",
    "columns_to_exclude = ['SalePrice','LogSalePrice']\n",
    "features = df_encoded.drop(columns_to_exclude, axis = 1).columns\n",
    "\n",
    "# Create variables\n",
    "X_tr, y_tr, X_te, y_te = create_variables(features, 'LogSalePrice')\n",
    "\n",
    "# Linear regression\n",
    "y_pred = fit_lr(X_tr, y_tr, X_te)\n",
    "rmse_lr = RMSE(y_te, y_pred)\n",
    "mae_lr = MAE(10**y_te, 10**y_pred)\n",
    "#mae_lr = MAE(y_te, y_pred)\n",
    "\n",
    "# Huber Loss\n",
    "y_pred_hl = fit_hl(X_tr, y_tr, X_te)\n",
    "rmse_hl = RMSE(y_te, y_pred_hl)\n",
    "mae_hl = MAE(10**y_te, 10**y_pred_hl)\n",
    "rmse_lr_TRAIN = RMSE(y_tr, y_pred)\n",
    "print('RMSE linear regression on TRAIN set: {:.3f}'.format(rmse_lr_TRAIN))\n",
    "print('RMSE linear regression: {:.3f}'.format(rmse_lr))\n",
    "print('RMSE Huber Loss: {:.3f}'.format(rmse_hl))\n",
    "print('MAE linear regression: {:.3f}'.format(mae_lr))\n",
    "print('MAE Huber Loss: {:.3f}'.format(mae_hl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features vs. polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does this comparison makes sens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr shape: (1213, 10) y_tr shape: (1213,) X_te shape: (1213, 10) y_te shape: (1213,)\n",
      "RMSE baseline: 0.178\n",
      "MAE baseline: 54125.121\n",
      "RMSE linear regression on TRAIN set: 0.229\n",
      "RMSE linear regression: 0.075\n",
      "MAE linear regression: 19108.628\n"
     ]
    }
   ],
   "source": [
    "# Select features\n",
    "features = ['OverallQualxTotalSF', 'Total SF', 'Overall Qual', 'Exter Qual', 'Gr Liv Area', 'Kitchen Qual', \n",
    "            'Total Bsmt SF', 'Garage Cars', 'Garage Area', 'Total Rooms']\n",
    "\n",
    "# Create X/y variables\n",
    "X_tr, y_tr, X_te, y_te = create_variables(features, 'LogSalePrice')\n",
    "\n",
    "# Median baseline\n",
    "rmse_baseline = RMSE(y_te, np.median(y_te))\n",
    "mae_baseline = MAE(10**y_te, np.median(10**y_te))\n",
    "\n",
    "print('RMSE baseline: {:.3f}'.format(rmse_baseline))\n",
    "print('MAE baseline: {:.3f}'.format(mae_baseline))\n",
    "\n",
    "# Linear regression\n",
    "y_pred = fit_lr(X_tr, y_tr, X_te)\n",
    "rmse_lr = RMSE(y_te, y_pred)\n",
    "mae_lr = MAE(10**y_te, 10**y_pred)\n",
    "rmse_lr_TRAIN = RMSE(y_tr, y_pred)\n",
    "print('RMSE linear regression on TRAIN set: {:.3f}'.format(rmse_lr_TRAIN))\n",
    "print('RMSE linear regression: {:.3f}'.format(rmse_lr))\n",
    "print('MAE linear regression: {:.3f}'.format(mae_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['OverallQualxTotalSF', 'OverallQualxTotalSF_1', 'OverallQualxTotalSF_2', 'Total SF', 'Total SF_1', 'Total SF_2', 'Overall Qual', 'Overall Qual_1', 'Overall Qual_2', 'Exter Qual', 'Exter Qual_1', 'Exter Qual_2', 'Gr Liv Area', 'Gr Liv Area_1', 'Gr Liv Area_2', 'Kitchen Qual', 'Kitchen Qual_1', 'Kitchen Qual_2', 'Total Bsmt SF', 'Total Bsmt SF_1', 'Total Bsmt SF_2', 'Garage Cars', 'Garage Cars_1', 'Garage Cars_2', 'Garage Area', 'Garage Area_1', 'Garage Area_2', 'Total Rooms', 'Total Rooms_1', 'Total Rooms_2']\n",
      "X_tr shape: (1213, 30) y_tr shape: (1213,) X_te shape: (1213, 30) y_te shape: (1213,)\n",
      "RMSE baseline: 0.178\n",
      "MAE baseline: 54125.121\n",
      "RMSE linear regression: 0.087\n",
      "RMSE linear regression on TRAIN set: 0.236\n",
      "MAE linear regression: 19172.987\n"
     ]
    }
   ],
   "source": [
    "# Select features\n",
    "features = create_features(['OverallQualxTotalSF', 'Total SF', 'Overall Qual', 'Exter Qual', 'Gr Liv Area', 'Kitchen Qual', \n",
    "            'Total Bsmt SF', 'Garage Cars', 'Garage Area', 'Total Rooms'])\n",
    "\n",
    "# Create X/y variables\n",
    "X_tr, y_tr, X_te, y_te = create_variables(features, 'LogSalePrice')\n",
    "\n",
    "# Median baseline\n",
    "rmse_baseline = RMSE(y_te, np.median(y_te))\n",
    "mae_baseline = MAE(10**y_te, np.median(10**y_te))\n",
    "\n",
    "print('RMSE baseline: {:.3f}'.format(rmse_baseline))\n",
    "print('MAE baseline: {:.3f}'.format(mae_baseline))\n",
    "\n",
    "# Linear regression\n",
    "y_pred = fit_lr(X_tr, y_tr, X_te)\n",
    "rmse_lr = RMSE(y_te, y_pred)\n",
    "mae_lr = MAE(10**y_te, 10**y_pred)\n",
    "rmse_lr_TRAIN = RMSE(y_tr, y_pred)\n",
    "print('RMSE linear regression on TRAIN set: {:.3f}'.format(rmse_lr_TRAIN))\n",
    "print('RMSE linear regression: {:.3f}'.format(rmse_lr))\n",
    "print('MAE linear regression: {:.3f}'.format(mae_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ill conditionoing : utiliser ridge regression\n",
    "#checker collinear features\n",
    "# colonnes identiques ? ou colonnes avec données qui changent pas ou peu (variable avec peu d'info à supprimer)\n",
    "#puis voir notebook \"encoding cat var\" pour OHE sur validation set : fonction reindex de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding regularization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot models\n",
    "sale_price = X_te[:, 0] \n",
    "plt.scatter(sale_price, y_te, s=10, label='test points')\n",
    "plt.scatter(sale_price, y_pred_hl, s=10, label='predictions (huber loss)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the error metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FRED:\n",
    "You can get the MAE scores in dollars by raising your predictions to power 10: MAE(10**y_te, 10**y_pred) where y_te and y_pred are in \"log10-dollars\". In this project, the MAE metric is very important to get a more intuitive score to report - an MAE of 50,000 means that your predictions are on average 50 thousand dollars away from the observed price. Thanks for asking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comparison\n",
    "mae_values = [mae_baseline, mae_lr, mae_lr2, mae_wdnwd]\n",
    "titles = ['median', 'lr', 'lr new features', 'two models']\n",
    "\n",
    "xcor = np.arange(len(mae_values))\n",
    "plt.bar(xcor, mae_values)\n",
    "plt.xticks(xcor, titles)\n",
    "\n",
    "plt.ylabel('MAE')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
